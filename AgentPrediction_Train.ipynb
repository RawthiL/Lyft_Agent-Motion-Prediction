{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib plots within notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, sys, shutil\n",
    "import pickle\n",
    "\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.dataset import EgoDataset, AgentDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.visualization import draw_trajectory, TARGET_POINTS_COLOR, PREDICTED_POINTS_COLOR, REFERENCE_TRAJ_COLOR\n",
    "from l5kit.geometry import transform_points\n",
    "import l5kit\n",
    "print('Using l5kit version: '+l5kit.__version__)\n",
    "\n",
    "\n",
    "\n",
    "# Custom libs\n",
    "sys.path.insert(0, './LyftAgent_lib')\n",
    "from LyftAgent_lib import train_support as lyl_ts\n",
    "from LyftAgent_lib import topologies as lyl_nn\n",
    "\n",
    "# Print Code Version\n",
    "import git\n",
    "def print_git_info(path, nombre):\n",
    "   repo = git.Repo(path)\n",
    "   print('Using: %s \\t branch %s \\t commit hash %s'%(nombre, repo.active_branch.name, repo.head.object.hexsha))\n",
    "   changed = [ item.a_path for item in repo.index.diff(None) ]\n",
    "   if len(changed)>0:\n",
    "       print('\\t\\t WARNING -- modified files:')\n",
    "       print(changed)    \n",
    "print_git_info('.', 'LyftAgent_lib')\n",
    "\n",
    "\n",
    "import platform\n",
    "print(\"python: \"+platform.python_version())\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "print('Using TensorFlow version: '+tf.__version__)\n",
    "print('Using Keras version: '+keras.__version__)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"\"\n",
    "# get config\n",
    "cfg = load_config_data(\"./AgentPrediction_config.yaml\")\n",
    "# Fill defaul classes\n",
    "cfg = lyl_ts.fill_defaults(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch to restart training (0 means start over)\n",
    "restart_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loss functions and coupling list\n",
    "# During training these are summed and wheighted like: loss_function[0]*loss_couplings[0] + ... + loss_function[n]*loss_couplings[n] \n",
    "loss_function = [lyl_ts.L_loss_single2mult, lyl_ts.L2_loss]\n",
    "loss_couplings = [1.0, 1.0]"
   ]
  },
  {
   "source": [
    "### Process config parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameters\n",
    "model_map_input_shape      = (cfg[\"raster_params\"][\"raster_size\"][0],\n",
    "                              cfg[\"raster_params\"][\"raster_size\"][1])\n",
    "\n",
    "base_image_arch            = cfg[\"model_params\"][\"base_image_model\"]\n",
    "base_image_preprocess      = cfg[\"model_params\"][\"base_image_preprocess\"]\n",
    "\n",
    "num_future_frames          = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "\n",
    "num_hist_frames            = cfg[\"model_params\"][\"history_num_frames\"]\n",
    "\n",
    "\n",
    "histEnc_recurrent_unit     = cfg[\"model_params\"][\"history_encoder_recurrent_unit\"]\n",
    "histEnc_recurrent_unit_num = cfg[\"model_params\"][\"history_encoder_recurrent_units_number\"]\n",
    "pathDec_recurrent_unit     = cfg[\"model_params\"][\"path_generation_decoder_recurrent_unit\"]\n",
    "pathDec_recurrent_unit_num = cfg[\"model_params\"][\"path_generation_decoder_recurrent_units_number\"]\n",
    "\n",
    "\n",
    "\n",
    "gen_batch_size             = cfg[\"train_data_loader\"][\"batch_size\"]\n",
    "gen_lr_list                = cfg[\"training_params\"][\"gen_lr_list\"]\n",
    "gen_lr_lims                = cfg[\"training_params\"][\"gen_lr_lims\"]\n",
    "\n",
    "\n",
    "number_of_scenes           = cfg[\"training_params\"][\"number_of_scenes\"]\n",
    "frames_per_scene           = cfg[\"training_params\"][\"frames_per_scene\"]\n",
    "randomize_frames           = cfg[\"training_params\"][\"randomize_frames\"]\n",
    "randomize_scenes           = cfg[\"training_params\"][\"randomize_scenes\"]\n",
    "epochs_train               = cfg[\"training_params\"][\"epochs_train\"]\n",
    "teacher_force_list         = cfg[\"training_params\"][\"teacher_force_list\"]\n",
    "teacher_force_lims         = cfg[\"training_params\"][\"teacher_force_lims\"]\n",
    "\n",
    "\n",
    "use_teacher_force          = cfg[\"training_params\"][\"use_teacher_force\"]\n",
    "init_decoder_on_history    = cfg[\"training_params\"][\"init_decoder_on_history\"]\n",
    "retrain_inputs_image_model = cfg[\"training_params\"][\"retrain_inputs_image_model\"]\n",
    "retrain_all_image_model    = cfg[\"training_params\"][\"retrain_all_image_model\"]\n",
    "\n",
    "future_steps_train_list    = cfg[\"training_params\"][\"future_steps_train_list\"]\n",
    "future_steps_train_lims    = cfg[\"training_params\"][\"future_steps_train_lims\"]\n",
    "use_modulate_future_steps  = cfg[\"training_params\"][\"use_modulate_future_steps\"]\n",
    "\n",
    "\n",
    "model_version              = cfg[\"model_params\"][\"version\"]\n",
    "use_fading                 = cfg[\"model_params\"][\"use_fading\"]\n",
    "\n",
    "use_angle                  = cfg[\"model_params\"][\"use_angle\"]\n",
    "\n",
    "increment_net              = cfg[\"model_params\"][\"increment_net\"]\n",
    "\n",
    "mruv_guiding               = cfg[\"model_params\"][\"mruv_guiding\"]\n",
    "mruv_model_trainable       = cfg[\"model_params\"][\"mruv_model_trainable\"]\n",
    "\n",
    "\n",
    "# Append flags to output name\n",
    "loss_names = ['Likelihood', 'MSE']\n",
    "if mruv_model_trainable:\n",
    "    loss_names.append('mruv_V_Loss')\n",
    "    loss_names.append('mruv_A_Loss')\n",
    "    loss_names.append('mruv_Conf_Loss')\n",
    "\n",
    "# Set mru_model trainable flag\n",
    "train_imgModel = retrain_inputs_image_model or retrain_all_image_model\n",
    "\n",
    "# Checl model version and set forward pass \n",
    "isBaseModel = False\n",
    "if model_version == 'Base':\n",
    "    isBaseModel = True\n",
    "    forward_pass_use = lyl_nn.modelBaseline_forward_pass\n",
    "    save_path = './output_Baseline'\n",
    "elif model_version == 'V1':\n",
    "    forward_pass_use = lyl_nn.modelV1_forward_pass\n",
    "    save_path = './output_V1_likelihood'\n",
    "elif model_version == 'V2':\n",
    "    forward_pass_use = lyl_nn.modelV2_forward_pass\n",
    "    save_path = './output_V2_noAttn_big_multiLoss_imgRetrain'\n",
    "    if mruv_guiding:\n",
    "        save_path += '_mruvGuided'\n",
    "    if mruv_model_trainable:\n",
    "        save_path += '_mruvModel'\n",
    "    cfg[\"model_params\"][\"history_encoder_recurrent_units_number\"] = cfg[\"model_params\"][\"path_generation_decoder_recurrent_units_number\"]\n",
    "\n",
    "\n",
    "\n",
    "# Get image preprocessing function (depends on image encoding base architecture)\n",
    "if base_image_preprocess == None:\n",
    "    base_image_preprocess_fcn = lambda x: x\n",
    "else:\n",
    "    try:\n",
    "        base_image_preprocess_fcn = getattr(keras.applications, base_image_preprocess.split('.')[0])\n",
    "        base_image_preprocess_fcn = getattr(base_image_preprocess_fcn, base_image_preprocess.split('.')[1])\n",
    "    except:\n",
    "        raise Exception('Base image pre-processing not found. Requested function: %s'%base_image_preprocess) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = LocalDataManager()\n",
    "dataset_path = dm.require(cfg[\"train_data_loader\"][\"key\"])\n",
    "zarr_dataset = ChunkedDataset(dataset_path)\n",
    "zarr_dataset.open(cached=False)\n",
    "print(zarr_dataset)\n",
    "rast = build_rasterizer(cfg, dm)\n",
    "train_dataset = AgentDataset(cfg, zarr_dataset, rast, min_frame_future = 10)\n",
    "number_of_scenes = len(train_dataset.dataset.scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = lyl_ts.get_tf_dataset(train_dataset, \n",
    "                                         num_hist_frames,\n",
    "                                         model_map_input_shape,\n",
    "                                         num_future_frames,\n",
    "                                         randomize_frame=randomize_frames,\n",
    "                                         randomize_scene=randomize_scenes, \n",
    "                                         num_scenes=number_of_scenes, \n",
    "                                         frames_per_scene = frames_per_scene)\n",
    "\n",
    "# Map sample pre-processing function\n",
    "tf_train_dataset = tf_train_dataset.map(lambda x: lyl_ts.tf_get_input_sample(x, \n",
    "                                                                             image_preprocess_fcn=base_image_preprocess_fcn, \n",
    "                                                                             use_fading = use_fading,\n",
    "                                                                             use_angle = use_angle))\n",
    "# Set batch size\n",
    "tf_train_dataset = tf_train_dataset.batch(batch_size=gen_batch_size)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_val = LocalDataManager()\n",
    "dataset_path_val = dm_val.require(cfg[\"val_data_loader\"][\"key\"])\n",
    "zarr_dataset_val = ChunkedDataset(dataset_path_val)\n",
    "zarr_dataset_val.open(cached=False)\n",
    "print(zarr_dataset_val)\n",
    "rast_val = build_rasterizer(cfg, dm_val)\n",
    "validation_dataset = AgentDataset(cfg, zarr_dataset_val, rast_val, min_frame_future = 10)\n",
    "number_of_scenes_val = len(validation_dataset.dataset.scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_validation_dataset = lyl_ts.get_tf_dataset(validation_dataset, \n",
    "                                              num_hist_frames,\n",
    "                                              model_map_input_shape,\n",
    "                                              num_future_frames,\n",
    "                                              randomize_frame=True,\n",
    "                                              randomize_scene=True, \n",
    "                                              num_scenes=number_of_scenes_val, \n",
    "                                              frames_per_scene = frames_per_scene)\n",
    "\n",
    "# Map sample pre-processing function\n",
    "tf_validation_dataset = tf_validation_dataset.map(lambda x: lyl_ts.tf_get_input_sample(x,                                                                                                                                  image_preprocess_fcn=base_image_preprocess_fcn,\n",
    "                                                                                      use_fading = use_fading,\n",
    "                                                                                      use_angle = use_angle))\n",
    "# Set batch size\n",
    "tf_validation_dataset = tf_validation_dataset.batch(batch_size=gen_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if restart_epoch>0:\n",
    "    # Pick up from previous step    \n",
    "    model_list = lyl_ts.load_models(save_path, 'epoch_%d'%(restart_epoch), \n",
    "                         load_img_model = (retrain_inputs_image_model or retrain_all_image_model), \n",
    "                         isBaseModel = isBaseModel,\n",
    "                         mruv_guiding = mruv_guiding,\n",
    "                         mruv_model_trainable = mruv_model_trainable)\n",
    "\n",
    "    ImageEncModel = model_list[0]\n",
    "    HistEncModel = model_list[1]\n",
    "    PathDecModel = model_list[2]\n",
    "    mruv_model = model_list[3]\n",
    "\n",
    "else:\n",
    "    \n",
    "    # ---------------------- IMAGE ENCODER --------------------------\n",
    "    # Load pretrained image processing model\n",
    "    try:\n",
    "        base_model_builder = getattr(keras.applications, base_image_arch)\n",
    "    except:\n",
    "        raise Exception('Base image processing model not found. Reuquested model: %s'%base_image_arch)\n",
    "\n",
    "\n",
    "    base_img_model = base_model_builder(include_top=False, weights='imagenet')\n",
    "\n",
    "    ImageEncModel = lyl_nn.imageEncodingModel(base_img_model, cfg)\n",
    "\n",
    "    # ---------------------- PATH HISTORY ENCODER ------------------\n",
    "    if not isBaseModel:\n",
    "        HistEncModel = lyl_nn.pathEncodingModel(cfg)\n",
    "    else:\n",
    "        HistEncModel = None\n",
    "    \n",
    "    if mruv_guiding:\n",
    "        if mruv_model_trainable:\n",
    "            mruv_model  = lyl_nn.mruvModel(cfg, ImageEncModel)\n",
    "        else:\n",
    "            mruv_model  = lyl_ts.get_velocity_and_acceleration\n",
    "    else:\n",
    "        mruv_model = None\n",
    "\n",
    "    # ---------------------- PATH DECODER --------------------------\n",
    "    if model_version == 'Base':\n",
    "        PathDecModel = lyl_nn.pathDecoderModel_Baseline(cfg, ImageEncModel)\n",
    "    elif model_version == 'V1':\n",
    "        PathDecModel = lyl_nn.pathDecoderModel_V1(cfg, ImageEncModel, HistEncModel)\n",
    "    elif model_version == 'V2':\n",
    "        PathDecModel = lyl_nn.pathDecoderModel_V2(cfg, ImageEncModel, HistEncModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ImageEncModel.summary()\n",
    "tf.keras.utils.plot_model(ImageEncModel, show_shapes=True, show_layer_names=True, \n",
    "                              to_file=os.path.join(save_path,'ImageEncModel.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not isBaseModel:\n",
    "    HistEncModel.summary()\n",
    "    tf.keras.utils.plot_model(HistEncModel, show_shapes=True, show_layer_names=True, \n",
    "                              to_file=os.path.join(save_path,'HistEncModel.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mruv_guiding and mruv_model_trainable:\n",
    "    mruv_model.summary()\n",
    "    tf.keras.utils.plot_model(mruv_model, show_shapes=True, show_layer_names=True, \n",
    "                              to_file=os.path.join(save_path,'mruv_model.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PathDecModel.summary()\n",
    "tf.keras.utils.plot_model(PathDecModel, show_shapes=True, show_layer_names=True, \n",
    "                              to_file=os.path.join(save_path,'PathDecModel.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "source": [
    "### Setup TensorBoard"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up TensorBoard\n",
    "logdir = os.path.join(save_path,'TensorBoard_outs')\n",
    "\n",
    "if os.path.exists(logdir) and restart_epoch==0:\n",
    "    shutil.rmtree(logdir)\n",
    "tb_writer = tf.summary.create_file_writer(os.path.join(logdir,'train'), name = 'train')\n",
    "\n",
    "tb_writer_val = tf.summary.create_file_writer(os.path.join(logdir,'validation'), name = 'validation')\n",
    "\n",
    "# Its really ugly... but you can get it if you want it...\n",
    "get_graph = False\n"
   ]
  },
  {
   "source": [
    "### Setup optimizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_gen = keras.optimizers.Adam(lr=1.0, beta_1=0.9, beta_2=0.99, epsilon=1.0e-8)\n",
    "train_genL2_loss = keras.metrics.Mean(name='train_gen_L2_loss')\n",
    "\n",
    "# Load optimizer state\n",
    "if restart_epoch>0:\n",
    "    if os.path.exists(os.path.join(os.path.join(save_path,'OptimizerStates'), 'epoch_%d.npy'%(restart_epoch))):\n",
    "        # Get list of trainable variables\n",
    "        train_vars = ImageEncModel.trainable_variables\n",
    "        if not isBaseModel:\n",
    "            train_vars += HistEncModel.trainable_variables\n",
    "        train_vars += PathDecModel.trainable_variables\n",
    "        if mruv_model_trainable:\n",
    "            train_vars += mruv_model.trainable_variables\n",
    "                    \n",
    "        lyl_ts.load_optimizer_state(os.path.join(save_path,'OptimizerStates'), 'epoch_%d'%(restart_epoch), optimizer_gen, train_vars)\n",
    "    else:\n",
    "        print('Warning - Optimizer state not loaded, using blank optimizer.')\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "source": [
    "### Train!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------- Set initial parameters -------------------------------\n",
    "teacher_force_base = 1.0\n",
    "teacher_force = teacher_force_base   \n",
    "if restart_epoch > 0:\n",
    "    epoch_ini = restart_epoch+1\n",
    "else:\n",
    "    epoch_ini = 1\n",
    "futureSteps_infer = num_future_frames\n",
    "h_idx_all = list()\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Run for the given number of epochs\n",
    "for epoch in range(epoch_ini, epochs_train+1):\n",
    "\n",
    "    # Using the \"train\" TensorBoard file\n",
    "    with tb_writer.as_default():\n",
    "\n",
    "        # Step index for this epoch\n",
    "        idx_gen_train = 0\n",
    "        # Number of steps per epoch to run\n",
    "        steps_per_epoch = int(np.floor(number_of_scenes*frames_per_scene/gen_batch_size))\n",
    "        # Global step index (grows indefinitelly with the epochs)\n",
    "        this_step_num = idx_gen_train+(steps_per_epoch*(epoch-1))\n",
    "\n",
    "        # ----------------------------- Set future steos to train on -------------------------\n",
    "        if use_modulate_future_steps:\n",
    "            # Modulate number of future steps to train on\n",
    "            futureSteps_infer = lyl_ts.get_future_steps_train(future_steps_train_list, \n",
    "                                                            future_steps_train_lims, \n",
    "                                                            epoch, \n",
    "                                                            futureSteps_infer)\n",
    "        with tf.name_scope(\"Train_params\"):\n",
    "            tf.summary.scalar('obj_steps', futureSteps_infer, step=this_step_num)\n",
    "\n",
    "        # ------------------------------------------------------------------------------------\n",
    "    \n",
    "        # ----------------------------- Set teacher force value ------------------------------\n",
    "        if not isBaseModel:\n",
    "            if use_teacher_force:\n",
    "                # Modulate teacher force\n",
    "                teacher_force = lyl_ts.get_teacher_force_weight(teacher_force_list, \n",
    "                                                        teacher_force_lims, \n",
    "                                                        epoch, \n",
    "                                                        teacher_force, \n",
    "                                                        linearize=True)\n",
    "                if teacher_force<=0.0:\n",
    "                    use_teacher_force = False\n",
    "                    print('Teacher force deactivated.')\n",
    "\n",
    "            with tf.name_scope(\"Train_params\"):\n",
    "                tf.summary.scalar('teacher_force', teacher_force, step=this_step_num)\n",
    "        # ------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        # ----------------------------- Set learning rate value ------------------------------\n",
    "        # Update learning rate\n",
    "        this_lr = lyl_ts.update_lr(gen_lr_list, gen_lr_lims, epoch, optimizer_gen)\n",
    "        with tf.name_scope(\"Train_params\"):\n",
    "            tf.summary.scalar('learning_rate', this_lr, step=this_step_num)\n",
    "        \n",
    "        # ------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        # Flush stdout to avoid tqdm overlap\n",
    "        sys.stdout.flush()\n",
    "                                \n",
    "        train_genL2_loss_aux = 0\n",
    "        \n",
    "\n",
    "        # List of hard examples\n",
    "        # This is a list ot those examples where the error was 5x larger than mean\n",
    "        h_example_idxs = list()\n",
    "        h_example_loss = list()\n",
    "        h_example_mean = list()\n",
    "        example_log = list()\n",
    "        \n",
    "        # Set tqdm progress bar\n",
    "        train_dataset_prog_bar = tqdm(tf_train_dataset, total=steps_per_epoch)\n",
    "        # Iterate over the training dataset once\n",
    "        # (Each complete iteration will shield a different, random, frame set)\n",
    "        for (thisSampleMapComp, thisSampeHistPath, thisSampeTargetPath, \n",
    "            thisHistAvail, thisTargetAvail, \n",
    "            thisTimeStamp, thisTrackID, thisRasterFromAgent, thisWorldFromAgent, thisCentroid, \n",
    "            thisSampleIdx) in train_dataset_prog_bar:\n",
    "\n",
    "            # Update step num\n",
    "            this_step_num = idx_gen_train+(steps_per_epoch*(epoch-1))\n",
    "\n",
    "            # If the batch size of this mini-batch is not the same as the \n",
    "            # expected by the net, the training loop is finished (we loose only a few random frames)\n",
    "            if thisSampleMapComp.shape[0] < gen_batch_size:\n",
    "                break\n",
    "\n",
    "            # If the graph is being recorded, start the tracing\n",
    "            if get_graph:\n",
    "                tf.summary.trace_on(graph=True, profiler=True)\n",
    "                       \n",
    "\n",
    "            # Run the correct train step depending on the model\n",
    "            if isBaseModel:\n",
    "                step_losses, gradients_out  = lyl_ts.generator_train_step_Base(thisSampleMapComp,\n",
    "                                                                        thisSampeTargetPath, \n",
    "                                                                        thisTargetAvail,\n",
    "                                                                        ImageEncModel,\n",
    "                                                                        PathDecModel, \n",
    "                                                                        optimizer_gen, \n",
    "                                                                        train_genL2_loss,\n",
    "                                                                        forward_pass_use,\n",
    "                                                                        loss_use = loss_function,\n",
    "                                                                        gradient_clip_value = 10.0)\n",
    "            else:\n",
    "                PathDecModel.reset_states()\n",
    "                HistEncModel.reset_states()\n",
    "                \n",
    "                step_losses, gradients_out = lyl_ts.generator_train_step(thisSampleMapComp,\n",
    "                                                                        thisSampeHistPath, \n",
    "                                                                        thisSampeTargetPath, \n",
    "                                                                        thisHistAvail, \n",
    "                                                                        thisTargetAvail,\n",
    "                                                                        ImageEncModel,\n",
    "                                                                        HistEncModel, \n",
    "                                                                        PathDecModel, \n",
    "                                                                        optimizer_gen, \n",
    "                                                                        train_genL2_loss,\n",
    "                                                                        tf.constant(tf.zeros(PathDecModel.inputs[-1].shape)),\n",
    "                                                                        forward_pass_use,\n",
    "                                                                        loss_use = loss_function,\n",
    "                                                                        loss_couplings = loss_couplings,\n",
    "                                                                        stepsInfer = futureSteps_infer,\n",
    "                                                                        use_teacher_force=use_teacher_force,\n",
    "                                                                        teacher_force_weight = tf.constant(teacher_force, \n",
    "                                                                                                                dtype=tf.float32),\n",
    "                                                                        gradient_clip_value = 10.0,\n",
    "                                                                        stop_gradient_on_prediction = False,\n",
    "                                                                        increment_net = increment_net,\n",
    "                                                                        mruv_guiding = mruv_guiding,\n",
    "                                                                        mruv_model = mruv_model, \n",
    "                                                                        mruv_model_trainable = mruv_model_trainable)\n",
    "\n",
    "            # If the graph was recorded, save it and stop the tracing\n",
    "            if get_graph:\n",
    "                tf.summary.trace_export(\n",
    "                    name=\"train_step_trace\",\n",
    "                    step=0,\n",
    "                    profiler_outdir=logdir)\n",
    "                tf.summary.trace_off()\n",
    "            get_graph = False\n",
    "\n",
    "\n",
    "            # Analyze train step output\n",
    "            thisL2 = train_genL2_loss.result()\n",
    "            if np.isnan(thisL2):\n",
    "                raise Exception('Bad potato... step %d'%idx_gen_train)\n",
    "                \n",
    "            # -------------------------- Update progress bar --------------------------------------\n",
    "            # Get step compound loss\n",
    "            train_genL2_loss_aux += thisL2\n",
    "            train_genL2_loss.reset_states()\n",
    "            print_gen_L2 = train_genL2_loss_aux/(idx_gen_train+1)\n",
    "\n",
    "            # Update progress bar\n",
    "            msg_string = '(Epoch %d/%d) Gen. Loss: %.2f (last %.2f) '%(epoch,\n",
    "                                                                            epochs_train,\n",
    "                                                                            print_gen_L2, \n",
    "                                                                            thisL2)\n",
    "            if use_teacher_force and not isBaseModel:\n",
    "                msg_string += '(t.f. = %.2f)'%teacher_force\n",
    "            train_dataset_prog_bar.set_description(msg_string)\n",
    "\n",
    "            # ------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # ------------------------------- Log the hard examples data -------------------------\n",
    "            comp_loss = 0\n",
    "            for step_loss, k in zip(step_losses, loss_couplings):\n",
    "                comp_loss += k*step_loss.numpy() \n",
    "            for thisLoss, thisIDX in zip(comp_loss, thisSampleIdx):\n",
    "                example_log.append(thisIDX)\n",
    "                if (thisLoss > 10.0*print_gen_L2):\n",
    "                    h_example_idxs.append(thisIDX)\n",
    "                    h_example_loss.append(thisLoss)\n",
    "                    h_example_mean.append(print_gen_L2)\n",
    "                                \n",
    "            # ------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # ------------------------------ Save info to tensorboard ----------------------------\n",
    "            with tf.name_scope(\"Loss_metrics\"):\n",
    "                for this_name, this_loss in zip(loss_names, step_losses):\n",
    "                    tf.summary.scalar(this_name, np.mean(this_loss.numpy()), step=this_step_num)\n",
    "\n",
    "            grad_out_count = 0\n",
    "            if train_imgModel:\n",
    "                with tf.name_scope(\"Gradient_ImgEncModel\"):\n",
    "                    for grad, var in zip(gradients_out[grad_out_count], ImageEncModel.trainable_variables):\n",
    "                        tf.summary.scalar(var.name+'_norm', np.linalg.norm(var.numpy()), step=this_step_num)\n",
    "                grad_out_count += 1\n",
    "            if not isBaseModel:\n",
    "                with tf.name_scope(\"Gradient_HistEncModel\"):\n",
    "                    for grad, var in zip(gradients_out[grad_out_count], HistEncModel.trainable_variables):\n",
    "                        tf.summary.scalar(var.name+'_norm', np.linalg.norm(var.numpy()), step=this_step_num)\n",
    "                    grad_out_count += 1\n",
    "            with tf.name_scope(\"Gradient_PathDecModel\"):\n",
    "                for grad, var in zip(gradients_out[grad_out_count], PathDecModel.trainable_variables):\n",
    "                    tf.summary.scalar(var.name+'_norm', np.linalg.norm(var.numpy()), step=this_step_num)\n",
    "                grad_out_count += 1\n",
    "            if mruv_model_trainable:\n",
    "                with tf.name_scope(\"Gradient_mruvModel\"):\n",
    "                    for grad, var in zip(gradients_out[grad_out_count], mruv_model.trainable_variables):\n",
    "                        tf.summary.scalar(var.name+'_norm', np.linalg.norm(var.numpy()), step=this_step_num)\n",
    "                grad_out_count += 1\n",
    "\n",
    "            if this_step_num % 100 == 0:\n",
    "                if train_imgModel:\n",
    "                    with tf.name_scope(\"ImageEncodingModel\"):\n",
    "                        for weights, layer in zip(ImageEncModel.get_weights(), ImageEncModel.trainable_variables):\n",
    "                            tf.summary.histogram(layer.name, weights, step=this_step_num)\n",
    "                if not isBaseModel:\n",
    "                    with tf.name_scope(\"HistoryEncodingModel\"):\n",
    "                        for weights, layer in zip(HistEncModel.get_weights(), HistEncModel.trainable_variables):\n",
    "                            tf.summary.histogram(layer.name, weights, step=this_step_num)\n",
    "                with tf.name_scope(\"PathDecoderModel\"):\n",
    "                    for weights, layer in zip(PathDecModel.get_weights(), PathDecModel.trainable_variables):\n",
    "                        tf.summary.histogram(layer.name, weights, step=this_step_num)\n",
    "                if mruv_model_trainable:\n",
    "                    with tf.name_scope(\"Gradient_mruvModel\"):\n",
    "                        for weights, layer in zip(mruv_model.get_weights(), mruv_model.trainable_variables):\n",
    "                            tf.summary.histogram(layer.name, weights, step=this_step_num)\n",
    "                tb_writer.flush()\n",
    "\n",
    "\n",
    "            # ------------------------------------------------------------------------------------\n",
    "\n",
    "            # Update this epoch train step\n",
    "            idx_gen_train += 1\n",
    "\n",
    "            \n",
    "        # --------------------------- Save Models -------------------------------------------\n",
    "        if retrain_inputs_image_model or retrain_all_image_model:\n",
    "            lyl_ts.save_model(ImageEncModel, os.path.join(save_path,'ImageEncModel'), 'epoch_%d'%epoch, use_keras=True)\n",
    "        elif epoch == 1:\n",
    "            lyl_ts.save_model(ImageEncModel, os.path.join(save_path,'ImageEncModel'), 'all_epochs', use_keras=True)\n",
    "        if not isBaseModel:\n",
    "            lyl_ts.save_model(HistEncModel, os.path.join(save_path,'HistEncModel'), 'epoch_%d'%epoch, use_keras=True)\n",
    "        lyl_ts.save_model(PathDecModel, os.path.join(save_path,'PathDecModel'), 'epoch_%d'%epoch, use_keras=True)\n",
    "        if mruv_model_trainable:\n",
    "            lyl_ts.save_model(mruv_model, os.path.join(save_path,'mruvModel'), 'epoch_%d'%epoch, use_keras=True)\n",
    "        lyl_ts.save_optimizer_state(optimizer_gen, os.path.join(save_path,'OptimizerStates'), 'epoch_%d'%epoch)\n",
    "\n",
    "        # ------------------------------------------------------------------------------------\n",
    "\n",
    "        # -------------------------- Save list of hard samples -------------------------------\n",
    "        h_example_idxs = np.array(h_example_idxs)\n",
    "        h_example_loss = np.array(h_example_loss)\n",
    "        h_example_mean = np.array(h_example_mean)\n",
    "        file_out = open(os.path.join(save_path,'epoch_%d_h_idx.txt'%epoch),\"w\") \n",
    "        for idx, loss, media in zip(h_example_idxs, h_example_loss, h_example_mean):\n",
    "            file_out.write('%d : \\t %g (%g)\\n'%(idx, loss, media))\n",
    "        file_out.close()\n",
    "        file_out = open(os.path.join(save_path,'epoch_%d_sample_log_idx.txt'%epoch),\"w\") \n",
    "        for idx in example_log:\n",
    "            file_out.write('%d, '%idx)\n",
    "        file_out.close()\n",
    "        # ------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # Perform validation using the \"validation\" TensorBoard file\n",
    "    with tb_writer_val.as_default():\n",
    "\n",
    "        # Validate\n",
    "        if (epoch%10 == 0):\n",
    "            # Once every ten, a full validation step\n",
    "            # (it is not really a complete run, because the dataset is built with a given \"frames_per_scene\")\n",
    "            out_metrics = lyl_ts.validate_model(tf_validation_dataset, \n",
    "                                ImageEncModel, HistEncModel, PathDecModel, forward_pass_use, \n",
    "                                increment_net = increment_net,\n",
    "                                mruv_guiding = mruv_guiding, \n",
    "                                mruv_model = mruv_model,\n",
    "                                mruv_model_trainable = mruv_model_trainable,\n",
    "                                all_metrics = True, base_model = isBaseModel)\n",
    "        else:\n",
    "            out_metrics = lyl_ts.validate_model(tf_validation_dataset, \n",
    "                                ImageEncModel, HistEncModel, PathDecModel, forward_pass_use, \n",
    "                                increment_net = increment_net,\n",
    "                                mruv_guiding = mruv_guiding, \n",
    "                                mruv_model = mruv_model,\n",
    "                                mruv_model_trainable = mruv_model_trainable,\n",
    "                                all_metrics = True,\n",
    "                                steps_validate = 100, stepsInfer = futureSteps_infer, base_model = isBaseModel)\n",
    "        \n",
    "        \n",
    "        with tf.name_scope(\"Loss_metrics\"):\n",
    "            tf.summary.scalar('MSE', out_metrics[0], step=this_step_num)\n",
    "            tf.summary.scalar('Likelihood', out_metrics[1], step=this_step_num)\n",
    "            tf.summary.scalar('TD(0)', out_metrics[2][0], step=this_step_num)\n",
    "            tf.summary.scalar('TD(10)', out_metrics[2][10], step=this_step_num)\n",
    "            tf.summary.scalar('TD(25)', out_metrics[2][25], step=this_step_num)\n",
    "            tf.summary.scalar('TD(T)', out_metrics[2][-1], step=this_step_num)\n",
    "            tf.summary.scalar('TD(mean)', np.mean(out_metrics[2]), step=this_step_num)\n",
    "\n",
    "        tb_writer_val.flush()\n",
    "\n",
    "        \n",
    "\n",
    "    print('')   \n",
    "    h_idx_all.append(np.unique(h_example_idxs))\n",
    "    print(np.unique(h_example_idxs).shape[0])\n",
    "\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single sample tests"
   ]
  },
  {
   "source": [
    "### Process a validation sample"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample batch\n",
    "for (valSampleMapComp, valSampeHistPath, valSampeTargetPath, \n",
    "         valHistAvail, valTargetAvail, \n",
    "     valTimeStamp, valTrackID, valRasterFromAgent, valWorldFromAgent, valCentroid, valSampleIdx) in tf_validation_dataset:\n",
    "    break\n",
    "\n",
    "# Process it\n",
    "PathDecModel.reset_states()\n",
    "HistEncModel.reset_states()\n",
    "valPredPath = forward_pass_use(valSampleMapComp,\n",
    "                                        valSampeHistPath,\n",
    "                                        valHistAvail,\n",
    "                                        50, \n",
    "                                        ImageEncModel, HistEncModel, PathDecModel,\n",
    "                                        use_teacher_force=False, target_path=valSampeTargetPath, increment_net = increment_net,\n",
    "                                                    mruv_guiding = mruv_guiding,\n",
    "                                                    mruv_model = mruv_model,\n",
    "                                                    mruv_model_trainable = mruv_model_trainable)\n",
    "\n",
    "valPredPath = valPredPath.numpy()\n",
    "valLoss = lyl_ts.L_loss_single2mult(valPredPath, valSampeTargetPath, valTargetAvail)\n",
    "valLoss = valLoss.numpy()\n",
    "\n",
    "print('Mean likelihood ot this batch: %0.2f'%np.mean(valLoss))\n"
   ]
  },
  {
   "source": [
    "### Plot input, predicted and expected path"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_sample = np.random.randint(gen_batch_size)\n",
    "num_targets = np.sum(valTargetAvail.numpy(), axis=1)[idx_sample].astype(np.int32)\n",
    "\n",
    "print('Sample num.: %d (%d target points)'%(valSampleIdx[idx_sample], num_targets))\n",
    "print('Timestamp: %d \\t TrackID %d'%(valTimeStamp[idx_sample], valTrackID[idx_sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_TRAJ_COLOR = (0, 255, 0)\n",
    "\n",
    "plt.figure(dpi=300)\n",
    "plt.subplot(1,3,1)\n",
    "img_aux = (np.copy(valSampleMapComp[idx_sample,:,:,:3].numpy()))\n",
    "img_aux = (((img_aux-np.min(img_aux))/(np.max(img_aux)-np.min(img_aux)))*255.0).astype(np.int32)\n",
    "draw_trajectory(img_aux,\n",
    "                transform_points(valSampeTargetPath[idx_sample,:num_targets,:2].numpy(), \n",
    "                                 valRasterFromAgent[idx_sample,:num_targets,:].numpy()),\n",
    "                TARGET_POINTS_COLOR)\n",
    "\n",
    "draw_trajectory(img_aux,\n",
    "                transform_points(valPredPath[idx_sample,:num_targets,:2], \n",
    "                                 valRasterFromAgent[idx_sample,:num_targets,:].numpy()),\n",
    "                PREDICTED_POINTS_COLOR)\n",
    "\n",
    "draw_trajectory(img_aux,\n",
    "                transform_points(valSampeHistPath[idx_sample,:,:2].numpy(), \n",
    "                                 valRasterFromAgent[idx_sample,:,:].numpy()),\n",
    "                HISTORY_TRAJ_COLOR)\n",
    "\n",
    "plt.imshow(img_aux, origin='botom')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(valSampleMapComp[idx_sample,:,:,3].numpy().astype(np.int32), origin='botom')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(valSampleMapComp[idx_sample,:,:,4].numpy().astype(np.int32), origin='botom')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "source": [
    "### Error plots"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(dpi = 150)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(valPredPath[idx_sample,:num_targets,0])\n",
    "plt.plot(valSampeTargetPath.numpy()[idx_sample,:num_targets,0])\n",
    "plt.ylabel('X position')\n",
    "plt.xlabel('steps')\n",
    "plt.legend(['predicted','ground truth'])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(valPredPath[idx_sample,:num_targets,1])\n",
    "plt.plot(valSampeTargetPath.numpy()[idx_sample,:num_targets,1])\n",
    "plt.ylabel('Y position')\n",
    "plt.xlabel('steps')\n",
    "plt.legend(['predicted','ground truth'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi = 150)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(valSampeTargetPath.numpy()[idx_sample,:num_targets,0], valPredPath[idx_sample,:num_targets,0], '*-')\n",
    "plt.plot(valSampeTargetPath[idx_sample,:num_targets,0], valSampeTargetPath[idx_sample,:num_targets,0], '-.')\n",
    "plt.ylabel('X position predicted')\n",
    "plt.xlabel('X position ground truth')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(valSampeTargetPath.numpy()[idx_sample,:num_targets,1], valPredPath[idx_sample,:num_targets,1], '*-')\n",
    "plt.plot(valSampeTargetPath[idx_sample,:num_targets,1], valSampeTargetPath[idx_sample,:num_targets,1], '-.')\n",
    "plt.ylabel('Y position predicted')\n",
    "plt.xlabel('Y position ground truth')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(lyl_ts)\n",
    "reload(lyl_nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}