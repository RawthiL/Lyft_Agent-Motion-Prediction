{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib plots within notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.dataset import AgentDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv\n",
    "from l5kit.geometry import transform_points\n",
    "\n",
    "\n",
    "# Custom libs\n",
    "sys.path.insert(0, './LyftAgent_lib')\n",
    "from LyftAgent_lib import train_support as lyl_ts\n",
    "from LyftAgent_lib import topologies as lyl_nn\n",
    "\n",
    "# Print Code Version\n",
    "import git\n",
    "def print_git_info(path, nombre):\n",
    "    repo = git.Repo(path)\n",
    "    print('Using: %s \\t branch %s \\t commit hash %s'%(nombre, repo.active_branch.name, repo.head.object.hexsha))\n",
    "    changed = [ item.a_path for item in repo.index.diff(None) ]\n",
    "    if len(changed)>0:\n",
    "        print('\\t\\t WARNING -- modified files:')\n",
    "        print(changed)\n",
    "    \n",
    "print_git_info('.', 'LyftAgent_lib')\n",
    "\n",
    "\n",
    "import platform\n",
    "print(\"python: \"+platform.python_version())\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "print('Using TensorFlow version: '+tf.__version__)\n",
    "print('Using Keras version: '+keras.__version__)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model loction\n",
    "path_load = ''\n",
    "# Test model base name\n",
    "net_base_name = ''\n",
    "\n",
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = ''\n",
    "# get config\n",
    "cfg = load_config_data(\"./AgentPrediction_config.yaml\")\n",
    "cfg = lyl_ts.fill_defaults(cfg)\n",
    "\n",
    "# Validation chopped dataset:\n",
    "eval_base_path = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_map_input_shape      = (cfg[\"raster_params\"][\"raster_size\"][0],\n",
    "                              cfg[\"raster_params\"][\"raster_size\"][1])\n",
    "num_hist_frames            = cfg[\"model_params\"][\"history_num_frames\"]\n",
    "num_future_frames          = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "\n",
    "increment_net              = cfg[\"model_params\"][\"increment_net\"]\n",
    "\n",
    "mruv_guiding               = cfg[\"model_params\"][\"mruv_guiding\"]\n",
    "mruv_model_trainable    = cfg[\"model_params\"][\"mruv_model_trainable\"]\n",
    "\n",
    "retrain_inputs_image_model = cfg[\"training_params\"][\"retrain_inputs_image_model\"]\n",
    "gen_batch_size             = cfg[\"train_data_loader\"][\"batch_size\"]\n",
    "\n",
    "\n",
    "model_version              = cfg[\"model_params\"][\"version\"]\n",
    "base_image_preprocess      = cfg[\"model_params\"][\"base_image_preprocess\"]\n",
    "use_fading                 = cfg[\"model_params\"][\"use_fading\"]\n",
    "\n",
    "use_angle                  = cfg[\"model_params\"][\"use_angle\"]\n",
    "\n",
    "isBaseModel = False\n",
    "if model_version == 'Base':\n",
    "    isBaseModel = True\n",
    "    forward_pass_use = lyl_nn.modelBaseline_forward_pass\n",
    "elif model_version == 'V1':\n",
    "    forward_pass_use = lyl_nn.modelV1_forward_pass\n",
    "elif model_version == 'V2':\n",
    "    forward_pass_use = lyl_nn.modelV2_forward_pass\n",
    "    \n",
    "\n",
    "# Get image preprocessing function (depends on image encoding base architecture)\n",
    "if base_image_preprocess == None:\n",
    "    base_image_preprocess_fcn = lambda x: x\n",
    "else:\n",
    "    try:\n",
    "        base_image_preprocess_fcn = getattr(keras.applications, base_image_preprocess.split('.')[0])\n",
    "        base_image_preprocess_fcn = getattr(base_image_preprocess_fcn, base_image_preprocess.split('.')[1])\n",
    "    except:\n",
    "        raise Exception('Base image pre-processing not found. Requested function: %s'%base_image_preprocess) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_list = lyl_ts.load_models(path_load, net_base_name, \n",
    "                         load_img_model = (retrain_inputs_image_model or retrain_all_image_model), \n",
    "                         isBaseModel = isBaseModel,\n",
    "                         mruv_guiding = mruv_guiding)\n",
    "\n",
    "ImageEncModel = model_list[0]\n",
    "HistEncModel = model_list[1]\n",
    "PathDecModel = model_list[2]\n",
    "mruv_model = model_list[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = LocalDataManager()\n",
    "rast = build_rasterizer(cfg, dm)\n",
    "\n",
    "dataset_path_test = dm.require(cfg[\"test_data_loader\"][\"key\"])\n",
    "test_zarr = ChunkedDataset(dataset_path_test)\n",
    "test_zarr.open()\n",
    "print(test_zarr)\n",
    "\n",
    "test_mask = np.load(f\"../prediction-dataset/scenes/mask.npz\")[\"arr_0\"]\n",
    "\n",
    "test_dataset = AgentDataset(cfg, test_zarr, rast, agents_mask=test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test_dataset = lyl_ts.get_tf_dataset(test_dataset, \n",
    "                                             num_hist_frames,\n",
    "                                             model_map_input_shape,\n",
    "                                             num_future_frames,\n",
    "                                             meta_dict_use = lyl_ts.meta_dict_pass)\n",
    "\n",
    "# Map sample pre-processing function\n",
    "tf_test_dataset = tf_test_dataset.map(lambda x: lyl_ts.tf_get_input_sample(x, \n",
    "                                                                             image_preprocess_fcn=base_image_preprocess_fcn, \n",
    "                                                                             use_fading = use_fading,\n",
    "                                                                             use_angle = use_angle))\n",
    "# Set batch size\n",
    "tf_test_dataset = tf_test_dataset.batch(batch_size=gen_batch_size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_coords_offsets_pd = []\n",
    "timestamps = []\n",
    "agent_ids = []\n",
    "\n",
    "\n",
    "\n",
    "test_dataset_prog_bar = tqdm(tf_test_dataset, total=int(np.ceil(len(test_dataset)/gen_batch_size)))\n",
    "test_dataset_prog_bar.set_description('Testing: ')\n",
    "for (thisSampleMapComp, thisSampeHistPath, thisSampeTargetPath, \n",
    "    thisHistAvail, thisTargetAvail, \n",
    "    thisTimeStamp, thisTrackID, thisRasterFromAgent, thisWorldFromAgent, thisCentroid, thisSampleIdx) in test_dataset_prog_bar:\n",
    "    \n",
    "    pad_size = gen_batch_size-thisSampleMapComp.shape[0]\n",
    "    if pad_size != 0:\n",
    "        # Create padded batch if necessary\n",
    "        aux_SampleMapComp = np.zeros((gen_batch_size,thisSampleMapComp.shape[1],thisSampleMapComp.shape[2],thisSampleMapComp.shape[3]), dtype = np.float32)\n",
    "        aux_SampeHistPath = np.zeros((gen_batch_size,thisSampeHistPath.shape[1],thisSampeHistPath.shape[2]), dtype = np.float32)\n",
    "        aux_SampeTargetPath = np.zeros((gen_batch_size,thisSampeTargetPath.shape[1],thisSampeTargetPath.shape[2]), dtype = np.float32)\n",
    "        aux_HistAvail = np.zeros((gen_batch_size,thisHistAvail.shape[1]), dtype = np.float32)\n",
    "        aux_TargetAvail = np.zeros((gen_batch_size,thisTargetAvail.shape[1]), dtype = np.float32)\n",
    "        aux_TimeStamp = np.zeros((gen_batch_size), dtype = np.float32)\n",
    "        aux_TrackID = np.zeros((gen_batch_size), dtype = np.float32)\n",
    "\n",
    "        aux_SampleMapComp[:gen_batch_size-pad_size,:,:,:] = thisSampleMapComp\n",
    "        aux_SampeHistPath[:gen_batch_size-pad_size,:,:] = thisSampeHistPath\n",
    "        aux_SampeTargetPath[:gen_batch_size-pad_size,:,:] = thisSampeTargetPath\n",
    "        aux_HistAvail[:gen_batch_size-pad_size,:] = thisHistAvail\n",
    "        aux_TargetAvail[:gen_batch_size-pad_size,:] = thisTargetAvail\n",
    "        aux_TimeStamp[:gen_batch_size-pad_size] = thisTimeStamp\n",
    "        aux_TrackID[:gen_batch_size-pad_size] = thisTrackID\n",
    "\n",
    "        thisSampleMapComp = aux_SampleMapComp\n",
    "        thisSampeHistPath = aux_SampeHistPath\n",
    "        thisSampeTargetPath = aux_SampeTargetPath\n",
    "        thisHistAvail = aux_HistAvail\n",
    "        thisTargetAvail = aux_TargetAvail\n",
    "        TimeStamp = aux_TimeStamp\n",
    "        thisTrackID = aux_TrackID\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Predict\n",
    "    if base_model:\n",
    "        predPath = forwardpass_use(thisSampleMapComp, ImageEncModel,  PathDecModel)\n",
    "    else:\n",
    "        PathDecModel.reset_states()\n",
    "        HistEncModel.reset_states()\n",
    "        predPath = forwardpass_use(thisSampleMapComp, thisSampeHistPath, thisHistAvail, 50,\n",
    "                                                ImageEncModel, HistEncModel, PathDecModel,\n",
    "                                                use_teacher_force=False,\n",
    "                                                increment_net = increment_net,\n",
    "                                                mruv_guiding = mruv_guiding,\n",
    "                                                mruv_model = mruv_model,\n",
    "                                                mruv_model_trainable = mruv_model_trainable)\n",
    "\n",
    "    predPath = predPath.numpy()\n",
    "\n",
    "    # convert agent coordinates into world offsets\n",
    "    predPath = predPath[:,:,:2]\n",
    "    world_from_agents = thisWorldFromAgent.numpy()\n",
    "    centroids = thisCentroid.numpy()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    for idx_sample in range(gen_batch_size-pad_size):\n",
    "        \n",
    "        # Save info\n",
    "        future_coords_offsets_pd.append(transform_points(predPath[idx_sample,:,:], thisWorldFromAgent.numpy()[idx_sample,:,:]) -thisCentroid.numpy()[idx_sample,:])\n",
    "        timestamps.append(thisTimeStamp[idx_sample].numpy())\n",
    "        agent_ids.append(thisTrackID[idx_sample])\n",
    "\n",
    "assert len(agent_ids) == len(test_dataset), \"Test data size not equal to dataset.\"\n",
    "    "
   ]
  },
  {
   "source": [
    "### Write result csv\n",
    "\n",
    "    Encode the predictions into a csv file. Coords can have an additional axis for multi-mode.\n",
    "    We handle up to MAX_MODES modes.\n",
    "    For the uni-modal case (i.e. all predictions have just a single mode), coords should not have the additional axis\n",
    "    and confs should be set to None. In this case, a single mode with confidence 1 will be written.\n",
    "    Args:\n",
    "        csv_path (str): path to the csv to write\n",
    "        timestamps (np.ndarray): (num_example,) frame timestamps\n",
    "        track_ids (np.ndarray): (num_example,) agent ids\n",
    "        coords (np.ndarray): (num_example x (modes) x future_len x num_coords) meters displacements\n",
    "        confs (Optional[np.ndarray]): (num_example x modes) confidence of each modes in each example.\n",
    "        Rows should sum to 1\n",
    "    Returns:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pred_csv('submission.csv',\n",
    "               timestamps=np.array(timestamps),\n",
    "               track_ids=np.array(agent_ids),\n",
    "               coords=np.array(future_coords_offsets_pd),\n",
    "              confs=None)"
   ]
  },
  {
   "source": [
    "# Validation \n",
    "\n",
    "This will perform validation against a chopped dataset. It will provide a value near the test value of the leader board."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace, rmse, average_displacement_error_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_val = LocalDataManager()\n",
    "\n",
    "# ===== GENERATE AND LOAD CHOPPED DATASET\n",
    "num_frames_to_chop = 100\n",
    "eval_cfg = cfg[\"val_data_loader\"]\n",
    "if not os.path.exists(eval_base_path):\n",
    "    eval_base_path = create_chopped_dataset(dm_val.require(eval_cfg[\"key\"]), \n",
    "                                            cfg[\"raster_params\"][\"filter_agents_threshold\"], \n",
    "                                            num_frames_to_chop,\n",
    "                                            cfg[\"model_params\"][\"future_num_frames\"],\n",
    "                                            MIN_FUTURE_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rast_val = build_rasterizer(cfg, dm_val)\n",
    "\n",
    "\n",
    "eval_zarr_path = os.path.join(eval_base_path, 'validate.zarr')\n",
    "eval_mask_path = os.path.join(eval_base_path, 'mask.npz') \n",
    "eval_gt_path =  os.path.join(eval_base_path, 'gt.csv') \n",
    "\n",
    "eval_zarr = ChunkedDataset(eval_zarr_path).open()\n",
    "eval_mask = np.load(eval_mask_path)[\"arr_0\"]\n",
    "# ===== INIT DATASET AND LOAD MASK\n",
    "validation_dataset = AgentDataset(cfg, eval_zarr, rast_val, agents_mask=eval_mask)\n",
    "# eval_dataloader = DataLoader(eval_dataset, shuffle=eval_cfg[\"shuffle\"], batch_size=eval_cfg[\"batch_size\"], \n",
    "#                              num_workers=eval_cfg[\"num_workers\"])\n",
    "print(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_validation_dataset = lyl_ts.get_tf_dataset(validation_dataset, \n",
    "                                             num_hist_frames,\n",
    "                                             model_map_input_shape,\n",
    "                                             num_future_frames,\n",
    "                                             meta_dict_use = lyl_ts.meta_dict_pass)\n",
    "\n",
    "# Map sample pre-processing function\n",
    "tf_validation_dataset = tf_validation_dataset.map(lambda x: lyl_ts.tf_get_input_sample(x, \n",
    "                                                                             image_preprocess_fcn=base_image_preprocess_fcn, \n",
    "                                                                             use_fading = use_fading,\n",
    "                                                                             use_angle = use_angle))\n",
    "# Set batch size\n",
    "tf_validation_dataset = tf_validation_dataset.batch(batch_size=gen_batch_size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_coords_offsets_pd = []\n",
    "timestamps = []\n",
    "agent_ids = []\n",
    "\n",
    "val_dataset_prog_bar = tqdm(tf_validation_dataset, total=int(np.ceil(len(validation_dataset)/gen_batch_size)))\n",
    "val_dataset_prog_bar.set_description('Validating: ')\n",
    "for (thisSampleMapComp, thisSampeHistPath, thisSampeTargetPath, \n",
    "    thisHistAvail, thisTargetAvail, \n",
    "    thisTimeStamp, thisTrackID, thisRasterFromAgent, thisWorldFromAgent, thisCentroid, thisSampleIdx) in val_dataset_prog_bar:\n",
    "    \n",
    "    pad_size = gen_batch_size-thisSampleMapComp.shape[0]\n",
    "    if pad_size != 0:\n",
    "        # Create padded batch if necessary\n",
    "        aux_SampleMapComp = np.zeros((gen_batch_size,thisSampleMapComp.shape[1],thisSampleMapComp.shape[2],thisSampleMapComp.shape[3]), dtype = np.float32)\n",
    "        aux_SampeHistPath = np.zeros((gen_batch_size,thisSampeHistPath.shape[1],thisSampeHistPath.shape[2]), dtype = np.float32)\n",
    "        aux_SampeTargetPath = np.zeros((gen_batch_size,thisSampeTargetPath.shape[1],thisSampeTargetPath.shape[2]), dtype = np.float32)\n",
    "        aux_HistAvail = np.zeros((gen_batch_size,thisHistAvail.shape[1]), dtype = np.float32)\n",
    "        aux_TargetAvail = np.zeros((gen_batch_size,thisTargetAvail.shape[1]), dtype = np.float32)\n",
    "        aux_TimeStamp = np.zeros((gen_batch_size), dtype = np.float32)\n",
    "        aux_TrackID = np.zeros((gen_batch_size), dtype = np.float32)\n",
    "\n",
    "        aux_SampleMapComp[:gen_batch_size-pad_size,:,:,:] = thisSampleMapComp\n",
    "        aux_SampeHistPath[:gen_batch_size-pad_size,:,:] = thisSampeHistPath\n",
    "        aux_SampeTargetPath[:gen_batch_size-pad_size,:,:] = thisSampeTargetPath\n",
    "        aux_HistAvail[:gen_batch_size-pad_size,:] = thisHistAvail\n",
    "        aux_TargetAvail[:gen_batch_size-pad_size,:] = thisTargetAvail\n",
    "        aux_TimeStamp[:gen_batch_size-pad_size] = thisTimeStamp\n",
    "        aux_TrackID[:gen_batch_size-pad_size] = thisTrackID\n",
    "\n",
    "        thisSampleMapComp = aux_SampleMapComp\n",
    "        thisSampeHistPath = aux_SampeHistPath\n",
    "        thisSampeTargetPath = aux_SampeTargetPath\n",
    "        thisHistAvail = aux_HistAvail\n",
    "        thisTargetAvail = aux_TargetAvail\n",
    "        TimeStamp = aux_TimeStamp\n",
    "        thisTrackID = aux_TrackID\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    # Predict\n",
    "    if base_model:\n",
    "        predPath = forwardpass_use(thisSampleMapComp, ImageEncModel,  PathDecModel)\n",
    "    else:\n",
    "        PathDecModel.reset_states()\n",
    "        HistEncModel.reset_states()\n",
    "        predPath = forwardpass_use(thisSampleMapComp, thisSampeHistPath, thisHistAvail, 50,\n",
    "                                                ImageEncModel, HistEncModel, PathDecModel,\n",
    "                                                use_teacher_force=False,\n",
    "                                                increment_net = increment_net,\n",
    "                                                mruv_guiding = mruv_guiding,\n",
    "                                                mruv_model = mruv_model,\n",
    "                                                mruv_model_trainable = mruv_model_trainable)\n",
    "    \n",
    "    predPath = predPath.numpy()\n",
    "\n",
    "    # convert agent coordinates into world offsets\n",
    "    predPath = predPath[:,:,:2]\n",
    "    world_from_agents = thisWorldFromAgent.numpy()\n",
    "    centroids = thisCentroid.numpy()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    for idx_sample in range(gen_batch_size-pad_size):\n",
    "        \n",
    "        # Save info\n",
    "        future_coords_offsets_pd.append(transform_points(predPath[idx_sample,:,:], thisWorldFromAgent.numpy()[idx_sample,:,:]) -thisCentroid.numpy()[idx_sample,:])\n",
    "        timestamps.append(thisTimeStamp[idx_sample].numpy())\n",
    "        agent_ids.append(thisTrackID[idx_sample])\n",
    "\n",
    "assert len(agent_ids) == len(validation_dataset), \"Validation data size not equal to dataset.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = '/tf/2020-10-Lyft/prediction-dataset/validate_chopped_100/validation_submission.csv'\n",
    "\n",
    "write_pred_csv(pred_path,\n",
    "               timestamps=np.array(timestamps),\n",
    "               track_ids=np.array(agent_ids, dtype=np.int32),\n",
    "               coords=np.array(future_coords_offsets_pd),\n",
    "               confs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metricas_out = compute_metrics_csv(eval_gt_path, pred_path, [neg_multi_log_likelihood, \n",
    "                                                             time_displace, \n",
    "                                                             rmse, \n",
    "                                                             average_displacement_error_mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name, metric_mean in metricas_out.items():\n",
    "    print(metric_name, metric_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}