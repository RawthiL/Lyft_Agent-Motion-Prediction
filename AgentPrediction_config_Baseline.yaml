# Config format schema number
format_version: 4

###################
## Model options
model_params:

  version: "Base"

  # Estimate yaw in addition to X and Y
  use_angle: False

  # If true all history image channels are computed as a fadded image. 
  # The most recent frames have higher intensity an it decays into the past
  use_fading: False

  # Base model for image feature extraction 
  # Note: Each model has its own preprocessing function, please select the right one...
  # base_image_model: "ResNet50"
  # base_image_preprocess: "resnet.preprocess_input"
  base_image_model: "MobileNetV2"
  base_image_preprocess: "mobilenet_v2.preprocess_input"

  
  # Number of fully connected layers used to generate the output coordinates (not counting last)
  num_path_decode_fc_layers: 1
  # Number of units in the FC layers used to generate the output coordinates
  path_decode_fc_units: [4096]
  # Activation of the FC layers used to generate the output coordinates
  path_decode_fc_activation: 'relu'

  
   
  # Number of history frames
  history_num_frames: 10
  # Steps between history frames
  history_step_size: 1
  # History sampling frequency
  history_delta_time: 0.1
  # Number of future frames
  future_num_frames: 50
  # Step size of future frames
  future_step_size: 1
  # Future steps sampling
  future_delta_time: 0.1

  

  
###################
## Training options
training_params: 

  # Learning rate list and epochs conforming a learning rate schedule
  gen_lr_list: [0.001, 0.0001, 0.00001, 0.00001]
  gen_lr_lims: [    2,      10,      20,   1000]
  # Number of scenes to be used in training
  number_of_scenes: 16000
  # Whether or not pick the scenes at random
  randomize_scenes: True
  # Frames to be read from a given scene
  frames_per_scene: 1
  # Whether or not pick the frames inside a given scene at random
  randomize_frames: True
  # Epochs to train, an epoch is a complete iteration over the "number_of_scenes", 
  # computing "frames_per_scene"x"number_of_scenes" samples.
  epochs_train: 1000
  
  # Whether or not retrain input layer of image processing model
  retrain_inputs_image_model: True
  # Whether or not retrain the whole image processing model
  retrain_all_image_model: True

  
  

###################
## Input raster parameters
raster_params:
  # raster image size [pixels]
  raster_size:
    - 224
    - 224
  # raster's spatial resolution [meters per pixel]: the size in the real world one pixel corresponds to.
  pixel_size:
    - 0.5
    - 0.5
  # From 0 to 1 per axis, [0.5,0.5] would show the ego centered in the image.
  ego_center:
    - 0.25
    - 0.5
  map_type: "py_semantic"
#   map_type: "py_satellite"


  # the keys are relative to the dataset environment variable
  satellite_map_key: "aerial_map/aerial_map.png"
  semantic_map_key: "semantic_map/semantic_map.pb"
  dataset_meta_key: "meta.json"

  # e.g. 0.0 include every obstacle, 0.5 show those obstacles with >0.5 probability of being
  # one of the classes we care about (cars, bikes, peds, etc.), >=1.0 filter all other agents.
  filter_agents_threshold: 0.5

  # whether to completely disable traffic light faces in the semantic rasterizer
  disable_traffic_light_faces: False

###################
## Data loader options
sample_data_loader:
  key: "scenes/sample.zarr"
  batch_size: 64
  shuffle: False
  num_workers: 4

train_data_loader:
  key: "scenes/train.zarr"
  batch_size: 32
  shuffle: True
  num_workers: 4

val_data_loader:
  key: "scenes/validate.zarr"
  batch_size: 32
  shuffle: False
  num_workers: 4
  
test_data_loader:
  key: "scenes/test.zarr"
  batch_size: 32
  shuffle: False
  num_workers: 4

