# Config format schema number
format_version: 4

###################
## Model options
model_params:

  version: "V2"
  CarNet: False # Only V1


  # The network is trained on calculating the increment from last step
  increment_net: True 

  # 
  mruv_guiding: True
  mruv_weight: 1.0
  mruv_model_trainable: True
  num_mruv_layers: 3
  mruv_units:  [256, 32, 8]

  # 
  pathDec_use_attention_hist: False
  pathDec_use_attention_img: False

  use_fading: True

  # Base model for image feature extraction 
  # Note: Each model has its own preprocessing function, please select the right one...
  base_image_model: "MobileNetV2"
  base_image_preprocess: "mobilenet_v2.preprocess_input"
  # base_image_model: "InceptionV3"
  # base_image_preprocess: "inception_v3.preprocess_input"
  # base_image_model: "ResNet50"
  # base_image_preprocess: "resnet.preprocess_input"

  
  # Type of recurrent units used in the ego path encoding layer (GRU, LSTM, etc)
  history_encoder_recurrent_unit: "GRU"
  # history_encoder_recurrent_unit: "LSTM"
  # Number of recurrent units used in the ego path encoding layer
  history_encoder_recurrent_units_number: 256
  # Number of dense layers to process history coordinates
  num_hist_encode_layers: 3
  # Units per dense layer to process history coordinates
  hist_encode_units: [8, 32, 128]
  # Activation of dense layers to process history coordinates
  hist_encode_activation: 'relu'
  # Type of recurrent units used in the ego path decoding layer (GRU, LSTM, etc)
  path_generation_decoder_recurrent_unit: "GRU"
  # path_generation_decoder_recurrent_unit: "LSTM"
  # Number of recurrent units used in the ego path decoding layer
  path_generation_decoder_recurrent_units_number: 256


  # Size of the intermediate space used in the attention mechanism
  pathDec_attention_pr_units: 64
  # Number of fully connected layers used to generate the output coordinates (not counting last)
  num_path_decode_fc_layers: 3
  # num_path_decode_fc_layers: 1
  # Number of units in the FC layers used to generate the output coordinates
  path_decode_fc_units: [1024, 128, 8]
  # path_decode_fc_units: [4096]
  # Activation of the FC layers used to generate the output coordinates
  path_decode_fc_activation: 'relu'
  # Path corruption noise level
  path_noise_level: 1.0
   
  history_num_frames: 10
  history_step_size: 1
  history_delta_time: 0.1

  future_num_frames: 50
  future_step_size: 1
  future_delta_time: 0.1

  use_angle: False

  
###################
## Training options
training_params: 

  # Learning rate of the path generator network
#   generator_learning_rate: 0.001
  # LEarning rate list and epochs conforming a learning rate schedule
  gen_lr_list: [0.001, 0.0001, 0.00001, 0.000005, 0.000001]
  gen_lr_lims: [    2,      10,      20,      40,      100]
  # gen_lr_list: [0.001, 0.0001, 0.00001, 0.000001, 0.000001]
  # gen_lr_lims: [   2,     10,      20,     30,       100]
  # Number of scenes to be used in training
  number_of_scenes: 16000
  # Whether or not pick the scenes at random
  randomize_scenes: True
  # Frames to be read from a given scene
  frames_per_scene: 1
  # Whether or not pick the frames inside a given scene at random
  randomize_frames: True
  # Epochs to train, an epoch is a complete iteration over the "number_of_scenes", 
  # computing "frames_per_scene"x"number_of_scenes" samples.
  #epochs_train: 100
  epochs_train: 100
  # Whether or not use teacher forcing during train
  use_teacher_force: True
  # The decay rate of the teacher force.
  # If set to 0 the teacher force will behave normally (next path is the target path)
  # If set to >0, the teacher force will be a linear interpolation of the target path 
  # and the generated path. 
  teacher_force_decay: 0.025 # 0.75
  # Teacher force list and limits conforming a teacher force modulation schedule
  # teacher_force_list: [1.0, 0.75, 0.5, 0.25, 0.0, 0.0]
  # teacher_force_lims: [  5,   10,  20,   80, 100, 120]
  # teacher_force_list: [1.0, 0.75, 0.5, 0.25, 0.0, 0.0, 0.0]
  # teacher_force_lims: [  2,    5,   7,   10,  15,  30, 100]
  teacher_force_list: [1.0, 0.5, 0.25, 0.0, 0.0, 0.0, 0.0]
  teacher_force_lims: [  2,    5,   7,   10,  15,  30, 100]
  # Whether or not initialize the decoder recurrent layer using the history paths
  init_decoder_on_history: True
  
  # Future steps to train on and limits conforming a the training schedule
  # future_steps_train_list: [50, 25, 15, 10, 5]
  # future_steps_train_lims: [20, 30, 40, 90, 100]
  # future_steps_train_list: [50, 25, 15, 10, 5]
  # future_steps_train_lims: [ 7, 10, 15, 20, 30]
  future_steps_train_list: [50, 50]
  future_steps_train_lims: [1, 100]
  # future_steps_train_list: [2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 11, 11, 12, 12, 14, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]
  # future_steps_train_lims: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 ,15, 16, 17, 18, 19, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60]
  # future_steps_train_list: [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 50]
  # future_steps_train_lims: [1,  2,  3 , 4,  5,  6,  7,  8,  9, 10, 60]
  use_modulate_future_steps: True


  # Whether or not retrain input layer of image processing model
  retrain_inputs_image_model: True
  # Whether or not retrain the whole image processing model
  retrain_all_image_model: True

  
  

  
  
  
  

###################
## Input raster parameters
raster_params:
  # raster image size [pixels]
  raster_size:
    - 224
    - 224
  # raster's spatial resolution [meters per pixel]: the size in the real world one pixel corresponds to.
  pixel_size:
    - 0.5
    - 0.5
  # From 0 to 1 per axis, [0.5,0.5] would show the ego centered in the image.
  ego_center:
    - 0.25
    - 0.5
  map_type: "py_semantic"
#   map_type: "py_satellite"


  # the keys are relative to the dataset environment variable
  satellite_map_key: "aerial_map/aerial_map.png"
  semantic_map_key: "semantic_map/semantic_map.pb"
  dataset_meta_key: "meta.json"

  # e.g. 0.0 include every obstacle, 0.5 show those obstacles with >0.5 probability of being
  # one of the classes we care about (cars, bikes, peds, etc.), >=1.0 filter all other agents.
  filter_agents_threshold: 0.5

  # whether to completely disable traffic light faces in the semantic rasterizer
  disable_traffic_light_faces: False

###################
## Data loader options
sample_data_loader:
  key: "scenes/sample.zarr"
  batch_size: 64
  shuffle: False
  num_workers: 4

train_data_loader:
  key: "scenes/train.zarr"
  batch_size: 32
  shuffle: True
  num_workers: 4

val_data_loader:
  key: "scenes/validate.zarr"
  batch_size: 32
  shuffle: False
  num_workers: 4
  
test_data_loader:
  key: "scenes/test.zarr"
  batch_size: 32
  shuffle: False
  num_workers: 4

